{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import time\n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len en : 10002\n",
      "Len vi : 10002\n"
     ]
    }
   ],
   "source": [
    "en, vi = [], []\n",
    "for file in glob.glob(\"./data/*.txt\"): \n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read() \n",
    "        list_text = text.split(\"\\n\") \n",
    "        for pair in list_text:\n",
    "            pair = pair.split(\"\\t\")\n",
    "            en.append(pair[0])\n",
    "            vi.append(pair[1])\n",
    "\n",
    "print(f\"Len en : {len(en)}\") \n",
    "print(f\"Len vi : {len(vi)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count words in language:\n",
      "en 8231\n",
      "vi 4824\n",
      "Len pairs: 6710\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2 \n",
    "UNK_token = 3 \n",
    "\n",
    "class Lang: \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2, \"UNK\": 3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\", 3: \"UNK\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, PAD, UNK\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def get_idx(self, word):\n",
    "        if word not in self.word2index:\n",
    "            return self.word2index['UNK']\n",
    "        return self.word2index[word]\n",
    "            \n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    # s = unicodeToAscii(s)\n",
    "    # s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, en, vi, reverse=False):\n",
    "    pairs = []\n",
    "    for i in range(len(en)):\n",
    "        pairs.append([normalizeString(en[i]), normalizeString(vi[i])])\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    print(\"Count words in language:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)   \n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "en_lang, vi_lang, pairs = readLangs('en', 'vi', en, vi, False)\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# filter pair for max lenght \n",
    "pairs = [pair for pair in pairs if len(pair[0].split(\" \")) < MAX_LENGTH and len(pair[1].split(\" \")) < MAX_LENGTH] \n",
    "print(f\"Len pairs: {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2index(lang: Lang, sentence: str): \n",
    "    sentence = normalizeString(sentence)\n",
    "    res = [SOS_token] \n",
    "    for word in sentence.split(\" \"):\n",
    "        if len(word) == 0: \n",
    "            continue\n",
    "        res.append(lang.get_idx(word))\n",
    "    res.append(EOS_token)\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "def get_dataloader(pairs, input_lang: Lang, output_lang: Lang, batch_size, max_lenght) -> DataLoader:\n",
    "    n = len(pairs)\n",
    "    input_pad = np.full((n, max_lenght), PAD_token, dtype=np.int32)\n",
    "    target_pad = np.full((n, max_lenght), PAD_token, dtype=np.int32)\n",
    "    for idx, pair in enumerate(pairs):\n",
    "        input = word2index(input_lang, pair[0])\n",
    "        target = word2index(output_lang, pair[1])\n",
    "        input_pad[idx, :len(input)] = input\n",
    "        target_pad[idx, :len(target)] = target\n",
    "    input_tensor = torch.tensor(input_pad, dtype=torch.long, device=device)\n",
    "    target_tensor = torch.tensor(target_pad, dtype=torch.long, device=device)\n",
    "    \n",
    "    dataset = TensorDataset(input_tensor, target_tensor) \n",
    "    sampler = RandomSampler(dataset) \n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 8231\n",
      "Output size: 4824\n",
      "Len train: 5368\n",
      "Len test: 1342\n"
     ]
    }
   ],
   "source": [
    "input_size = en_lang.n_words \n",
    "output_size = vi_lang.n_words \n",
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "print(f\"Input size: {input_size}\")\n",
    "print(f\"Output size: {output_size}\")\n",
    "\n",
    "MAX_LENGTH = MAX_LENGTH + 2 # add 2 for SOS and EOS token\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42) \n",
    "print(f\"Len train: {len(train_pairs)}\") \n",
    "print(f\"Len test: {len(test_pairs)}\")\n",
    "train_dataloader = get_dataloader(train_pairs, en_lang, vi_lang, batch_size=batch_size, max_lenght=MAX_LENGTH) \n",
    "test_dataloader = get_dataloader(test_pairs, en_lang, vi_lang, batch_size=batch_size, max_lenght=MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True) \n",
    "        \n",
    "    def forward(self, input): \n",
    "        \"\"\" forward encoder \n",
    "\n",
    "        Args:\n",
    "            input (tensor): shape (batch_size, max_length)\n",
    "\n",
    "        Returns:\n",
    "            outputs: shape (batch_size, max_length, hidden_size)\n",
    "            hidden: shape (num_layers, batch_size, hidden_size) \n",
    "            cell: shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, (hidden, cell) \n",
    "\n",
    "class DecoderSimple(nn.Module): \n",
    "    def __init__(self, output_size, hidden_size, num_layers, dropout):\n",
    "        super(DecoderSimple, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, encoder_cell, target_tensor = None):\n",
    "        \"\"\" forward in decoder \n",
    "\n",
    "        Args:\n",
    "            encoder_outputs (tensor): shape (batch_size, max_length, hidden_size)\n",
    "            encoder_hidden (tensor): shape (num_layers, batch_size, hidden_size)\n",
    "            encoder_cell (tensor): shape (num_layers, batch_size, hidden_size)\n",
    "            target_tensor (tensor, optional): shape (batch_size, max_seq). Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.shape[0] \n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "        decoder_outputs = [] \n",
    "        for i in range(MAX_LENGTH): \n",
    "            decoder_output, (decoder_hidden, decoder_cell) = self.forward_step(decoder_input, decoder_hidden, decoder_cell) \n",
    "            decoder_outputs.append(decoder_output) \n",
    "            if target_tensor is not None: \n",
    "                # teacher forcing \n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) \n",
    "            else: \n",
    "                # without teacher forcing \n",
    "                _, topi = decoder_output.topk(1) \n",
    "                decoder_input = topi.squeeze(1).detach()    # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) \n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) \n",
    "        \n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "        \n",
    "        \n",
    "    def forward_step(self, input, hidden, cell): \n",
    "        \"\"\" forward_step\n",
    "\n",
    "        Args:\n",
    "            input (tensor): input tensor has shape (batch_size, 1)\n",
    "            hidden (tensor): hidden tensor has shape (num_layers, batch_size, hidden_size)\n",
    "            cell (tensor): cell tensor has shape (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            output: shape (batch_size, 1, output_size)\n",
    "            hidden: shape (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input)    \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        output = self.fc(output)\n",
    "        return output, (hidden, cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderScaleDotAttn(nn.Module): \n",
    "    def __init__(self, output_size, hidden_size, num_layers, dropout): \n",
    "        super(DecoderScaleDotAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, encoder_cell, target_tensor = None): \n",
    "        batch_size = encoder_outputs.shape[0] \n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) \n",
    "        decoder_hidden = encoder_hidden \n",
    "        decoder_cell = encoder_cell \n",
    "        decoder_outputs = []\n",
    "        attn_weights = []\n",
    "        for i in range(MAX_LENGTH): \n",
    "            decoder_output, (decoder_hidden, decoder_cell), attn_w = self.forward_step(decoder_input, decoder_hidden, decoder_cell, encoder_outputs) \n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attn_weights.append(attn_w)\n",
    "            if target_tensor is not None: \n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) \n",
    "            else: \n",
    "                _, topi = decoder_output.topk(1) \n",
    "                decoder_input = topi.squeeze(1).detach()\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) \n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) \n",
    "        return decoder_outputs, decoder_hidden, attn_weights\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward_step(self, decoder_input, decoder_hidden, decoder_cell, encoder_outputs): \n",
    "        # use scale dot product attention\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        \"\"\"\n",
    "            calculate attention weights \n",
    "            encoder_outputs: key, value \n",
    "            embedded: query \n",
    "            attention_weights = score(Q, K) \n",
    "            attention_score = softmax(attention_weights)\n",
    "            context = attention_score * V \n",
    "            output = bmm (context, q) \n",
    "            -------------------------------\n",
    "            attn_w = query * key \n",
    "            attn_score = softmax(attn_w) \n",
    "            context = attn_score * value\n",
    "            output = context * query | mabey we can use linear layer to get output\n",
    "            \n",
    "            \n",
    "        \"\"\"\n",
    "        attn_weights = torch.bmm(encoder_outputs, embedded.transpose(1, 2))\n",
    "        attn_score = F.softmax(attn_weights, dim=1)\n",
    "        context = torch.bmm(attn_score.transpose(1, 2), encoder_outputs)  # shape (batch_size, 1, hidden_size)\n",
    "        output, (decoder_hidden, decoder_cell) = self.lstm(context, (decoder_hidden, decoder_cell))\n",
    "        output = self.fc(output)\n",
    "        return output, (decoder_hidden, decoder_cell), attn_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderAttn(nn.Module): \n",
    "    def __init__(self, output_size, hidden_size, num_layers, dropout): \n",
    "        super(DecoderAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout, batch_first=True) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = nn.Linear(hidden_size * 2, MAX_LENGTH)\n",
    "        self.attn_combine = nn.Linear(hidden_size * 2, hidden_size) \n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, encoder_cell, target_tensor = None): \n",
    "        batch_size = encoder_outputs.shape[0] \n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token) \n",
    "        decoder_hidden = encoder_hidden \n",
    "        decoder_cell = encoder_cell \n",
    "        decoder_outputs = []\n",
    "        attn_weights = []\n",
    "        for i in range(MAX_LENGTH): \n",
    "            decoder_output, (decoder_hidden, decoder_cell), attn_w = self.forward_step(decoder_input, decoder_hidden, decoder_cell, encoder_outputs) \n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attn_weights.append(attn_w)\n",
    "            if target_tensor is not None: \n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) \n",
    "            else: \n",
    "                _, topi = decoder_output.topk(1) \n",
    "                decoder_input = topi.squeeze(1).detach()\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) \n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) \n",
    "        return decoder_outputs, decoder_hidden, attn_weights\n",
    "    \n",
    "    def forward_step(self, decoder_input, decoder_hidden, decoder_cell, encoder_outputs): \n",
    "        \"\"\"\n",
    "            calculate attention weights \n",
    "            embedded: query shape (batch_size, 1, hidden_size) \n",
    "            encoder_outputs: key, value shape (batch_size, max_length, hidden_size) \n",
    "            attn_weights = score(Q, K) shape (batch_size, 1, max_length) \n",
    "            attn_score = softmax(attn_weights) shape (batch_size, 1, max_length) \n",
    "            context = attn_score * V shape (batch_size, 1, hidden_size) \n",
    "            rnn_input = [embedded, context] shape (batch_size, 1, hidden_size * 2)\n",
    "            rnn_input = linear(rnn_input) shape (batch_size, 1, hidden_size)\n",
    "            output = rnn(rnn_input) shape (batch_size, 1, hidden_size)\n",
    "            output = fc(output) shape (batch_size, 1, output_size)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(decoder_input)\n",
    "        attn_weights = torch.bmm(encoder_outputs, embedded.transpose(1, 2))\n",
    "        attn_score = F.softmax(attn_weights, dim=1)\n",
    "        context = torch.bmm(attn_score.transpose(1, 2), encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, context), dim=-1)\n",
    "        rnn_input = self.attn_combine(rnn_input)\n",
    "        output, (decoder_hidden, decoder_cell) = self.lstm(rnn_input, (decoder_hidden, decoder_cell))\n",
    "        output = self.fc(output)\n",
    "        return output, (decoder_hidden, decoder_cell), attn_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<04:54,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Time: 0.5610320568084717 - Loss: 6.755776246388753\n",
      "Eval - Time: 0.02927541732788086 - Loss: 4.574126113544811 - Score: 0.5044905971211346\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:06<04:43,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02922654151916504 - Loss: 3.5500499551946465 - Score: 0.6421722787538543\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [00:12<04:37,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029355764389038086 - Loss: 3.4341230392456055 - Score: 0.6792803629615375\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31/500 [00:18<04:32,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029212474822998047 - Loss: 3.3084082169966265 - Score: 0.7131284786225269\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [00:23<04:26,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029183626174926758 - Loss: 3.27895526452498 - Score: 0.7209075590865944\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [00:29<04:20,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Time: 0.5500040054321289 - Loss: 2.4977534725552513\n",
      "Eval - Time: 0.029334306716918945 - Loss: 3.2475086992437188 - Score: 0.7447799198331566\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [00:35<04:14,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029139041900634766 - Loss: 3.2499528364701704 - Score: 0.7461783157709317\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 71/500 [00:41<04:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02912116050720215 - Loss: 3.2295353412628174 - Score: 0.7557423241613453\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 81/500 [00:47<04:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029119253158569336 - Loss: 3.249952944842252 - Score: 0.7599190321790522\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/500 [00:52<03:57,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02924633026123047 - Loss: 3.236988804557107 - Score: 0.7709874222503937\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:58<03:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Time: 0.550602912902832 - Loss: 1.5777772693406968\n",
      "Eval - Time: 0.029290199279785156 - Loss: 3.2303108952262183 - Score: 0.7811510312387887\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 111/500 [01:04<03:45,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029109954833984375 - Loss: 3.2631807977503 - Score: 0.7879970128116497\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/500 [01:10<03:39,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02923417091369629 - Loss: 3.299551096829501 - Score: 0.7858939166426826\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 131/500 [01:16<03:34,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029120683670043945 - Loss: 3.329428867860274 - Score: 0.7902529280376837\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141/500 [01:21<03:28,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029155254364013672 - Loss: 3.3955915624445137 - Score: 0.7879013185171114\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/500 [01:27<03:22,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 - Time: 0.5503802299499512 - Loss: 0.7877627710501353\n",
      "Eval - Time: 0.029292821884155273 - Loss: 3.431558435613459 - Score: 0.7876513567729194\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/500 [01:33<03:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02933025360107422 - Loss: 3.4546300281177866 - Score: 0.7981223989464962\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 171/500 [01:39<03:10,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029227018356323242 - Loss: 3.5320239067077637 - Score: 0.7943936773174541\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 181/500 [01:45<03:05,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029186725616455078 - Loss: 3.5996378768574107 - Score: 0.7963927441560066\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/500 [01:50<02:59,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029115676879882812 - Loss: 3.638278982856057 - Score: 0.8020845621732344\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [01:56<02:53,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200 - Time: 0.5502557754516602 - Loss: 0.2719739984188761\n",
      "Eval - Time: 0.02926921844482422 - Loss: 3.701694683595137 - Score: 0.7993622880674202\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 211/500 [02:02<02:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029144287109375 - Loss: 3.752287604592063 - Score: 0.8065699997630476\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 221/500 [02:08<02:41,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02925848960876465 - Loss: 3.809311801737005 - Score: 0.8047202820674301\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 231/500 [02:14<02:35,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02908492088317871 - Loss: 3.8861407149921763 - Score: 0.7976962465130328\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 241/500 [02:19<02:30,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029207706451416016 - Loss: 3.918868823484941 - Score: 0.8051485122581323\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/500 [02:25<02:24,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250 - Time: 0.5504090785980225 - Loss: 0.07219966962223962\n",
      "Eval - Time: 0.029233932495117188 - Loss: 3.9804199608889492 - Score: 0.8044759855327464\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 261/500 [02:31<02:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029199600219726562 - Loss: 4.0033933466131035 - Score: 0.8103208652971277\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 271/500 [02:37<02:12,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02914738655090332 - Loss: 4.047618844292381 - Score: 0.8109041922693178\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 281/500 [02:43<02:07,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029108285903930664 - Loss: 4.0745837471701885 - Score: 0.8159954622999251\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 291/500 [02:48<02:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02924036979675293 - Loss: 4.135209647091952 - Score: 0.8087325385227989\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [02:54<01:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300 - Time: 0.5505993366241455 - Loss: 0.027163472381376084\n",
      "Eval - Time: 0.029306888580322266 - Loss: 4.112360239028931 - Score: 0.8096713484180106\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 311/500 [03:00<01:49,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029118776321411133 - Loss: 4.178733869032427 - Score: 0.81198002310229\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 321/500 [03:06<01:43,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02921152114868164 - Loss: 4.275933894244107 - Score: 0.8131931340382337\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 331/500 [03:12<01:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.0290377140045166 - Loss: 4.282607793807983 - Score: 0.8153396853040245\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 341/500 [03:17<01:32,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.028908252716064453 - Loss: 4.242939298803156 - Score: 0.8188644613210344\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 351/500 [03:23<01:26,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350 - Time: 0.5504281520843506 - Loss: 0.008814381934436304\n",
      "Eval - Time: 0.02919602394104004 - Loss: 4.280013192783702 - Score: 0.8186866999767205\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 361/500 [03:29<01:20,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.028900623321533203 - Loss: 4.345968593250621 - Score: 0.8182447534662277\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 371/500 [03:35<01:14,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02899169921875 - Loss: 4.399081446907737 - Score: 0.8164088169161499\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 381/500 [03:41<01:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029068470001220703 - Loss: 4.33463285186074 - Score: 0.8237260328523437\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 391/500 [03:46<01:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029191017150878906 - Loss: 4.419072649695656 - Score: 0.8197535877436587\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [03:52<00:57,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400 - Time: 0.550189733505249 - Loss: 0.004331664381814855\n",
      "Eval - Time: 0.029161930084228516 - Loss: 4.4171504540876905 - Score: 0.8225932206344911\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 411/500 [03:58<00:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02912163734436035 - Loss: 4.471344384280118 - Score: 0.821014935311871\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 421/500 [04:04<00:45,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029099225997924805 - Loss: 4.321079514243386 - Score: 0.8248322406973181\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 431/500 [04:10<00:40,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029065370559692383 - Loss: 4.413210522044789 - Score: 0.825713309784208\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 441/500 [04:15<00:34,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029120683670043945 - Loss: 4.482459913600575 - Score: 0.82476104585552\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [04:21<00:28,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450 - Time: 0.5504803657531738 - Loss: 0.0026413224737292956\n",
      "Eval - Time: 0.02912163734436035 - Loss: 4.5297346982088955 - Score: 0.8255956926030602\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 461/500 [04:27<00:22,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029074907302856445 - Loss: 4.514632550152865 - Score: 0.8272364786448564\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 471/500 [04:33<00:16,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029161691665649414 - Loss: 4.329861424186013 - Score: 0.834950917829254\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 481/500 [04:39<00:11,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.02901768684387207 - Loss: 4.4124267318032 - Score: 0.8383974985594307\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 491/500 [04:44<00:05,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval - Time: 0.029080867767333984 - Loss: 4.4653871276161885 - Score: 0.8366608694946103\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:50<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_size, hidden_size, num_layers, dropout).to(device) \n",
    "decoder = DecoderAttn(output_size, hidden_size, num_layers, dropout).to(device)\n",
    "learning_rate = 1e-4\n",
    "criterion = nn.NLLLoss() \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) \n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate) \n",
    "n_epochs = 500\n",
    "\n",
    "previous_score = 0 \n",
    "count = 0\n",
    "for epoch in tqdm(range(n_epochs)): \n",
    "    # train phase \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    time_epoch = time.time()\n",
    "    averge_loss = [] \n",
    "    for input_tensor, target_tensor in train_dataloader: \n",
    "        # zero the gradient\n",
    "        encoder_optimizer.zero_grad() \n",
    "        decoder_optimizer.zero_grad() \n",
    "        \n",
    "        # forward\n",
    "        encoder_outputs, (encoder_hidden, encoder_cell) = encoder(input_tensor) \n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, encoder_cell, target_tensor) \n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(decoder_outputs.view(-1, output_size), target_tensor.view(-1)) \n",
    "        loss.backward() \n",
    "        \n",
    "        # update weight\n",
    "        encoder_optimizer.step() \n",
    "        decoder_optimizer.step() \n",
    "        \n",
    "        averge_loss.append(loss.item()) \n",
    "\n",
    "    if epoch % 50 == 0: \n",
    "        print(f\"Epoch {epoch} - Time: {time.time() - time_epoch} - Loss: {np.mean(averge_loss)}\") \n",
    "    # eval phase\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    time_epoch = time.time() \n",
    "    averge_loss = [] \n",
    "    averge_score = [] \n",
    "    for input_tensor, target_tensor in test_dataloader: \n",
    "        with torch.no_grad(): \n",
    "            encoder_outputs, (encoder_hidden, encoder_cell) = encoder(input_tensor) \n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, encoder_cell, target_tensor) \n",
    "            loss = criterion(decoder_outputs.view(-1, output_size), target_tensor.view(-1)) \n",
    "            averge_loss.append(loss.item())\n",
    "            averge_score.append((decoder_outputs.argmax(-1) == target_tensor).sum().item() / (target_tensor != PAD_token).sum().item()) \n",
    "    averge_score = np.mean(averge_score)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Eval - Time: {time.time() - time_epoch} - Loss: {np.mean(averge_loss)} - Score: {averge_score}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), '/home/hoang.minh.an/anhalu-data/learning/deep-learning-from-scratch/nlp/seq2seq/save_model/encoder_model_attention_linear.pth')\n",
    "torch.save(decoder.state_dict(), '/home/hoang.minh.an/anhalu-data/learning/deep-learning-from-scratch/nlp/seq2seq/save_model/decoder_model_attention_linear.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS tôi thật ngu ngốc khi tin tưởng bạn. "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def evaluate(encoder, decoder, sentence): \n",
    "    with torch.no_grad(): \n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        input_tensor = torch.tensor(word2index(en_lang, sentence), dtype=torch.long, device=device).unsqueeze(0) \n",
    "        encoder_outputs, (encoder_hidden, encoder_cell) = encoder(input_tensor) \n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, encoder_cell) \n",
    "        decoder_outputs = decoder_outputs.argmax(-1).squeeze(0) \n",
    "        for idx in decoder_outputs: \n",
    "            token = vi_lang.index2word[idx.item()]\n",
    "            if token == \"EOS\": \n",
    "                break\n",
    "            print(token, end=\" \")\n",
    "            \n",
    "            \n",
    "encoder = Encoder(input_size, hidden_size, num_layers, dropout).to(device) \n",
    "decoder = DecoderAttn(output_size, hidden_size, num_layers, dropout).to(device) \n",
    "encoder.load_state_dict(torch.load('/home/hoang.minh.an/anhalu-data/learning/deep-learning-from-scratch/nlp/seq2seq/save_model/encoder_model_attention_linear.pth'))\n",
    "decoder.load_state_dict(torch.load('/home/hoang.minh.an/anhalu-data/learning/deep-learning-from-scratch/nlp/seq2seq/save_model/decoder_model_attention_linear.pth')) \n",
    "\n",
    "evaluate(encoder, decoder, \"I was a fool to trust you .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
